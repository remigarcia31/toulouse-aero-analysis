# ‚úàÔ∏è Analyse de Donn√©es de Vol ADS-B sur GCP (R√©gion Toulousaine) üá´üá∑

**Un projet Data Engineering End-to-End d√©montrant la construction d'un pipeline de donn√©es robuste, scalable et automatis√© sur Google Cloud Platform pour l'analyse du trafic a√©rien.**

---

## üéØ Objectif du Projet

Ce projet vise √† ing√©rer, traiter, stocker, orchestrer et visualiser les donn√©es publiques de suivi de vols ADS-B (Automatic Dependent Surveillance‚ÄìBroadcast) fournies par OpenSky Network, en se concentrant potentiellement sur la r√©gion de Toulouse, hub a√©ronautique majeur.

L'objectif n'est pas seulement technique, mais aussi de d√©montrer comment un pipeline data moderne sur GCP peut transformer des donn√©es brutes en insights actionnables, **r√©duisant ainsi le temps d'analyse** pour les parties prenantes (op√©rations a√©roportuaires, √©tudes environnementales, planification strat√©gique) et fournissant une **source de donn√©es fiable et √† jour** sur l'activit√© a√©rienne locale.

Ce repository sert de portfolio pour illustrer mes comp√©tences en Data Engineering sur l'√©cosyst√®me GCP.

## ‚ú® Fonctionnalit√©s et Points Cl√©s

* **Pipeline de Donn√©es E2E :** De l'ingestion brute √† la pr√©paration pour la visualisation, en passant par le traitement, le stockage et l'orchestration.
* **Architecture GCP Moderne :** Utilisation de services manag√©s et serverless pour la scalabilit√© et l'efficacit√© op√©rationnelle (Cloud Functions Gen2, Cloud Storage, BigQuery, Dataproc, Cloud Composer v2, Cloud Build).
* **Traitement de Donn√©es Scalable :** Utilisation d'Apache Spark (via PySpark sur Dataproc) pour traiter et transformer les donn√©es JSON brutes.
* **Stockage Optimis√© :** √âcriture des donn√©es trait√©es au format Parquet avec **partitionnement de type Hive** (ann√©e, mois, jour, heure) sur GCS pour des requ√™tes analytiques performantes. Utilisation de l'**√©crasement de partition dynamique**.
* **Data Warehousing Analytique :** Exposition des donn√©es trait√©es dans BigQuery via une **table externe partitionn√©e** pour des requ√™tes SQL efficaces, compl√©t√©e par des **vues SQL** pr√©-calculant des KPIs et facilitant l'analyse.
* **Orchestration Automatis√©e :** Utilisation de Cloud Composer v2 (Apache Airflow manag√©) pour planifier, ex√©cuter et surveiller le pipeline de traitement Spark (DAG Python).
* **Infrastructure as Code (IaC) :** D√©finition et gestion de l'infrastructure GCP (Buckets, Dataset BQ, IAM...) via **Terraform** pour la reproductibilit√© et la gestion versionn√©e.
* **Tests Automatis√©s :** Impl√©mentation de tests unitaires pour la logique de transformation PySpark (avec **pytest** et **chispa**) et pour la fonction d'ingestion (avec **pytest** et **unittest.mock**).
* **Int√©gration Continue (CI) :** Mise en place d'un pipeline **Cloud Build** d√©clench√© par Git pour automatiser la validation de l'infrastructure (Terraform Validate), le linting du code Python (`flake8`) et l'ex√©cution des tests unitaires (`pytest`).
* **Configuration S√©curis√©e :** Utilisation d'un fichier `.env` (ignor√© par Git) pour g√©rer les configurations sp√©cifiques √† l'environnement d'ex√©cution local (backfill).
* **Pr√©paration pour Visualisation :** Donn√©es et vues pr√™tes √† √™tre consomm√©es par un outil de BI comme Looker Studio.

## üèóÔ∏è Architecture

Le diagramme ci-dessous illustre le flux de donn√©es et les composants principaux du projet :

```mermaid
graph LR
    subgraph " "
        direction LR
        subgraph "Ingestion (Temps R√©el-Like)"
            direction TB
            OSN[("OpenSky Network API")] -- JSON --> CF(Cloud Function<br/> / Python)
            SCHED(Cloud Scheduler<br/>Toutes les 10 min) --> CF
            CF -- Fichiers JSON bruts --> GCS_L(GCS Landing<br/>YYYY/MM/DD/HH/)
        end

        subgraph "Traitement (Batch Horaire)"
            direction TB
            COMP(Cloud Composer<br/>**v2** / Airflow DAG<br/>@hourly) -- D√©clenche Job --> DP(Dataproc Cluster<br/>PySpark Script)
            DP -- Lit depuis --> GCS_L
            DP -- √âcrit Parquet partitionn√© --> GCS_P(GCS Processed<br/>/year=.../month=.../...)
        end

        subgraph "Stockage & Acc√®s"
            direction TB
            GCS_P -- Pointe vers --> BQ_EXT(BigQuery<br/>External Table<br/>flight_data_external)
            BQ_EXT -- Utilis√©e par --> BQ_VIEW(BigQuery Views<br/>vw_kpi_1, vw_kpi_2...)
        end

        subgraph "Consommation"
            direction TB
            BQ_VIEW -- Requ√™tes SQL / API --> USERS(Analystes / Applications)
            BQ_VIEW -- Connecteur BQ --> LOOKER(Looker Studio<br/>Dashboard)
        end

        subgraph "Gestion & CI/CD"
            direction RL
            subgraph "Code & Infra"
              GIT(Git Repository<br/>Code Source<br/>Terraform, Python<br/>SQL, DAG, Tests)
              TF(Terraform<br/>IaC)
              ENV(Fichier .env<br/>GitIgnored)
            end
            subgraph "Automatisation Build"
              CB(Cloud Build<br/>CI: Validate, Lint, Test<br/>CD: Deploy Infra/Code)
              PYTEST(Pytest<br/>Chispa, Mock)
              FLAKE8(Flake8<br/>Linter)
            end
            GIT -- Push --> CB
            TF --> GCP_RES(Ressources GCP<br/>GCS, BQ, IAM...)
            CB -- G√®re --> TF
            CB -- D√©ploie --> CF
            CB -- D√©ploie --> COMP(DAGs)
            CB -- Ex√©cute --> PYTEST
            CB -- Ex√©cute --> FLAKE8
        end
    end

    style GCS_L fill:#4285F4,stroke:#000,color:#fff
    style GCS_P fill:#4285F4,stroke:#000,color:#fff
    style CF fill:#DB4437,stroke:#000,color:#fff
    style SCHED fill:#DB4437,stroke:#000,color:#fff
    style DP fill:#F4B400,stroke:#000,color:#000
    style COMP fill:#F4B400,stroke:#000,color:#000
    style BQ_EXT fill:#0F9D58,stroke:#000,color:#fff
    style BQ_VIEW fill:#0F9D58,stroke:#000,color:#fff
    style LOOKER fill:#0F9D58,stroke:#000,color:#fff
    style TF fill:#623CE4,stroke:#000,color:#fff
    style CB fill:#466FBC,stroke:#000,color:#fff
    style GIT fill:#f5f5f5,stroke:#333,color:#333
    style PYTEST fill:#f5f5f5,stroke:#333,color:#333
    style FLAKE8 fill:#f5f5f5,stroke:#333,color:#333
    style ENV fill:#f5f5f5,stroke:#333,color:#333
```
**Flux D√©taill√© :**
1.  **Ingestion :** Cloud Scheduler d√©clenche (toutes les 10 min) une Cloud Function (Python). Celle-ci interroge l'API OpenSky Network et √©crit les donn√©es JSON brutes dans GCS Landing Zone (`YYYY/MM/DD/HH/`).
2.  **Orchestration :** Cloud Composer v2 ex√©cute un DAG Airflow (planifi√© `@hourly`).
3.  **Traitement :** Le DAG soumet un job PySpark √† un cluster Dataproc. Le job lit les JSON bruts de l'heure pr√©c√©dente depuis GCS Landing. Il nettoie, transforme les donn√©es, et les enrichit avec des colonnes de partition (year, month, day, hour). Il √©crit le r√©sultat au format Parquet dans GCS Processed Zone en utilisant le **partitionnement Hive** et l'**√©crasement dynamique des partitions**.
4.  **Acc√®s Analytique :** Une **table externe partitionn√©e** dans BigQuery (`flight_data_external`) pointe vers les fichiers Parquet sur GCS, permettant des requ√™tes SQL performantes gr√¢ce √† l'√©limination des partitions (partition pruning). Des **vues SQL** (`vw_*`) sont d√©finies dans un dossier `bigquery/views/` et cr√©√©es sur BigQuery pour simplifier l'acc√®s aux KPIs.
5.  **Consommation :** Les analystes peuvent interroger les vues/tables BigQuery via SQL, ou connecter des outils de BI comme Looker Studio pour cr√©er des dashboards interactifs.
6.  **Gestion :** L'infrastructure est d√©finie avec Terraform (`IaC`). Le code (Python, SQL, DAG, Terraform) est versionn√© avec Git. La configuration sensible locale est g√©r√©e via un fichier `.env` (ignor√© par Git).
7.  **Int√©gration Continue (CI) :** Cloud Build est d√©clench√© par les `push` Git. Il valide le code Terraform, installe les d√©pendances Python (y compris `pyspark`, `pytest`, `chispa`, `flake8`), ex√©cute le linter `flake8` et les tests unitaires `pytest` pour la Cloud Function et le script Spark. *(Note: L'ex√©cution des tests Spark dans Cloud Build peut n√©cessiter une attention particuli√®re concernant l'environnement Java).*

## üõ†Ô∏è Technologies Utilis√©es

* **Cloud Platform :** Google Cloud Platform (GCP)
* **Services GCP Principaux :**
    * Cloud Functions (**Gen 2**)
    * Cloud Storage (GCS)
    * Dataproc
    * BigQuery
    * Cloud Composer (**v2**, Airflow 2.x)
    * Cloud Scheduler
    * Cloud Build
    * IAM
    * Looker Studio
    * *(Optionnel: Secret Manager, Artifact Registry)*
* **Langages :** Python (3.11), SQL (GoogleSQL), Bash
* **Frameworks / Biblioth√®ques Cl√©s :**
    * PySpark (pour le traitement)
    * Apache Airflow (pour l'orchestration)
    * Pandas, Requests (dans Cloud Function)
    * google-cloud-python libraries
    * `pytest`, `chispa`, `unittest.mock`, `freezegun` (pour les tests)
    * `flake8` (pour le linting)
* **Infrastructure & CI/CD :** Terraform, Git, Docker (implicitement)
* **Concepts Cl√©s :** Partitionnement Hive, Tables Externes BigQuery, IaC, CI, Tests Unitaires, Mocking, Orchestration DAG.
* **Formats de Donn√©es :** JSON (brut), Parquet (trait√©)

## üìä Donn√©es Source

Les donn√©es proviennent de l'[API REST de OpenSky Network](https://openskynetwork.github.io/opensky-api/rest.html). Elles consistent en des "vecteurs d'√©tat" (state vectors) d'a√©ronefs transmis via ADS-B et d'autres syst√®mes, contenant des informations telles que :
* Identifiant `icao24`
* Indicatif d'appel (`callsign`)
* Position (`longitude`, `latitude`)
* Altitude (`baro_altitude`, `geo_altitude`)
* Vitesse (`velocity`)
* Cap (`true_track`)
* Taux de mont√©e/descente (`vertical_rate`)
* Statut au sol (`on_ground`)
* Timestamps (`time_position`, `last_contact`)
* Code transpondeur (`squawk`)
* Pays d'origine (`origin_country`)

L'API publique est utilis√©e, avec un filtrage g√©ographique appliqu√© lors de l'ingestion pour se concentrer sur la r√©gion d'int√©r√™t.

## ‚öôÔ∏è Installation et Ex√©cution (Instructions Haut Niveau)

Ce projet n√©cessite une configuration sp√©cifique sur GCP.

**Pr√©requis :**
* Compte Google Cloud avec facturation activ√©e (**Attention aux co√ªts** de Composer et Dataproc si actifs).
* `gcloud` CLI install√© et configur√©.
* `terraform` CLI install√©.
* `git` install√©.
* Python 3.11 (ou compatible) et `pip` pour l'environnement virtuel local.
* Java JDK (ex: 11) install√© localement avec `JAVA_HOME` configur√©.

**√âtapes :**
1.  **Cloner le D√©p√¥t :** `git clone https://github.com/remigarcia31/toulouse-aero-analysis.git`
2.  **Environnement Local :**
    * `cd toulouse-aero-analysis`
    * `python -m venv venv`
    * `source venv/bin/activate`
    * `pip install -r src/cloud_function_ingest/requirements.txt -r src/spark_job/requirements.txt -r requirements-dev.txt`
3.  **Configuration :**
    * Cr√©ez un fichier `.env` √† la racine (copiez depuis `.env.example`).
    * Assurez-vous que `.env` est dans `.gitignore`.
    * Remplissez les variables (`PROJECT_ID`, noms de buckets...).
4.  **Infrastructure :** `cd terraform/`, `terraform init`, `terraform apply`. (Cr√©e GCS, BQ Dataset, IAM...).
5.  **D√©ploiement Initial / CI :**
    * Le pipeline Cloud Build configur√© dans `cloudbuild.yaml` devrait se d√©clencher sur `git push`. Il ex√©cute `terraform validate`, `flake8`, `pytest` pour les diff√©rents composants.
    * Le d√©ploiement effectif des Cloud Functions, DAGs, etc., n'est pas encore inclus dans la CI/CD (voir Am√©liorations). Un d√©ploiement manuel initial (`gcloud functions deploy...`, `gsutil cp ...`) est n√©cessaire ou √† int√©grer √† la CI/CD.
6.  **Orchestration & Scheduler (Si besoin de les activer) :**
    * Cr√©ez/D√©marrez l'environnement Cloud Composer (`gcloud composer ...`).
    * Cr√©ez/Reprenez le job Cloud Scheduler (`gcloud scheduler ...`).
7.  **Backfill Historique (Optionnel - Manuel) :**
    * D√©marrez un cluster Dataproc (`gcloud dataproc clusters create ...`).
    * Utilisez le script `backfill_spark_jobs.sh` (configur√© via `.env`).
    * **SUPPRIMEZ** le cluster Dataproc apr√®s usage.
8.  **Lancement du Pipeline Orchestr√© :**
    * N√©cessite un environnement Composer actif.
    * Le DAG actuel (`aero_data_processing_pipeline`) cible un cluster Dataproc manuel (`aero-cluster-test`). Pour un fonctionnement autonome, il faut le modifier pour utiliser des **clusters √©ph√©m√®res** (voir Am√©liorations).
    * Activez le DAG et le Scheduler pour un fonctionnement continu.

## üìä R√©sultats & Visualisation

Les donn√©es trait√©es sont accessibles via les vues (`vw_*`) dans `toulouse-aero-analysis.aeronautics_data` dans BigQuery.

Un tableau de bord Looker Studio a √©t√© cr√©√© pour explorer interactivement ces donn√©es. Il inclut :
* Une carte de la position des avions.
* L'√©volution du nombre d'avions uniques par heure.
* La r√©partition du trafic par pays d'origine.
* Des indicateurs sur l'altitude et la vitesse moyennes.
* Des filtres par date et par pays.

**[TODO : Ins√©rez ici une capture d'√©cran de votre dashboard Looker Studio]**
`![Aper√ßu Dashboard Looker Studio](chemin/vers/screenshot_dashboard.png)`

**[TODO : Optionnel : ajoutez un lien si votre dashboard est public]**
`[Voir le Dashboard Interactif](LIEN_LOOKER_STUDIO_PUBLIC)`

## üöÄ Am√©liorations Possibles

* **CI/CD Compl√®te :** Ajouter les √©tapes de **D√©ploiement Continu (CD)** dans Cloud Build pour d√©ployer automatiquement Terraform, Cloud Function, DAG Airflow, scripts Spark.
* **Clusters Dataproc √âph√©m√®res :** **(Recommand√©)** Modifier le DAG Airflow pour utiliser `DataprocCreateClusterOperator` et `DataprocDeleteClusterOperator` afin de cr√©er/supprimer des clusters √† la demande, optimisant les co√ªts.
* **Monitoring & Alerting :** Configurer des alertes Cloud Monitoring / Airflow Callbacks en cas d'√©chec.
* **Data Quality Checks :** Int√©grer des tests de qualit√© de donn√©es (ex: via des op√©rateurs BigQuery dans Airflow, ou des outils comme dbt/Great Expectations).
* **Enrichissement des Donn√©es :** Joindre avec des bases de donn√©es externes (type d'avion, compagnie...).
* **Streaming R√©el :** Remplacer l'ingestion par Pub/Sub et Dataflow.
* **Tests :** Ajouter des tests d'int√©gration pour valider le flux complet.
* **S√©curit√© :** Affiner les permissions IAM au minimum requis.
* **Gestion de la Configuration :** Utiliser des variables Airflow ou Secret Manager pour la configuration utilis√©e par les DAGs.
* **Gestion du Backfill via Airflow :** Impl√©menter une logique de backfill plus robuste directement dans Airflow.

## üë§ Auteur

* **R√©mi GARCIA**
* **LinkedIn :** `https://www.linkedin.com/in/remi-garcia-31t12r/`
* **GitHub :** `https://github.com/remigarcia31`

---
